<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.3.3">Jekyll</generator><link href="https://hughxuechen.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://hughxuechen.github.io/" rel="alternate" type="text/html" hreflang="en"/><updated>2025-03-26T09:29:37+00:00</updated><id>https://hughxuechen.github.io/feed.xml</id><title type="html">blank</title><subtitle></subtitle><entry><title type="html">Reddit Data</title><link href="https://hughxuechen.github.io/blog/2024/reddit/" rel="alternate" type="text/html" title="Reddit Data"/><published>2024-09-07T00:00:00+00:00</published><updated>2024-09-07T00:00:00+00:00</updated><id>https://hughxuechen.github.io/blog/2024/reddit</id><content type="html" xml:base="https://hughxuechen.github.io/blog/2024/reddit/"><![CDATA[<h4 id="motivation">Motivation</h4> <p>Reddit is a treasure trove of data. It is a platform where users can submit content, comment on posts, and vote on submissions. It is a great source of data for a variety of reasons.</p> <h4 id="reddit-api">Reddit API</h4> <p>There are a lot of tutorials on how to use the Reddit API. I will not go into the details of how to use the API, but I will share some tips that I learned.</p> <p>The general idea is use praw to authenticate and then use the API to get the data. You need to <a href="https://www.reddit.com/prefs/apps">create an app</a> to get the credentials (“client_id” and “secret”).</p> <p>The critical problem I met was that Reddit has the rate limit and the date of data is not far from today. The data I got is only about 1k posts which is the latest at the time of my request. My longitudinal study needs more data and the data should be from the past.</p> <h4 id="project-arctic-shift">Project Arctic Shift</h4> <p>Luckily, I found a project called <a href="https://github.com/ArthurHeitmann/arctic_shift">Project Arctic Shift</a> which aims to archive all the posts and comments on Reddit. This Github repository is self-explanatory so I only mention several points that I think are important.</p> <ol> <li>Do not unzip the .zst file since it takes too much storage. Use code to read it and extract the data you need.</li> <li>If you are extracting the data and save in csv format in Python, be careful with the “selftext” field. It contains the main text of the post/comment. If it is too long, the file will be corrupted which create break lines in the rows.</li> </ol>]]></content><author><name></name></author><category term="Reddit"/><category term="API"/><summary type="html"><![CDATA[Some reflections on using Reddit data]]></summary></entry></feed>